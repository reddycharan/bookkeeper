#!/bin/sh
#
#/**
# * Copyright 2007 The Apache Software Foundation
# *
# * Licensed to the Apache Software Foundation (ASF) under one
# * or more contributor license agreements.  See the NOTICE file
# * distributed with this work for additional information
# * regarding copyright ownership.  The ASF licenses this file
# * to you under the Apache License, Version 2.0 (the
# * "License"); you may not use this file except in compliance
# * with the License.  You may obtain a copy of the License at
# *
# *     http://www.apache.org/licenses/LICENSE-2.0
# *
# * Unless required by applicable law or agreed to in writing, software
# * distributed under the License is distributed on an "AS IS" BASIS,
# * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# * See the License for the specific language governing permissions and
# * limitations under the License.
# */


## Bookie settings

## Some settings support configuration override for specific time range.
## For example one can set:
## gcWaitTime=1800000
## gcWaitTime@timerange0=900000
## 
## Time ranges defined as:
## <rangename>.start=<start time>
## <rangename>.end=<end time>
## Optional:
## <rangename>.day=<comma-separated list of days of the week>
## <rangename> consists of prefix "timerange" plus numeric id.
## Numeric id starts from 0 and incremented by 1. 
## Search for ranges stops on the first missing id and/or on the first range that misses 
## or has wrong value for the time or day.
## 
## Start and end time defined in ISO_LOCAL_TIME format (24 hr, local time zone)
## 
## Time ranges can overlap because different ranges can be applied to different groups of
## parameters.
## 
## Examples:
## 
## timerange0.start=09:00:00
## timerange0.end=17:59:59.999
## 
## timerange1.start=22:00
## timerange1.end=23:00
## timerange1.day=Saturday,Sunday
## 
## minorCompactionThreshold=0.2
## minorCompactionThreshold@timerange0=0.1
## 
## minorCompactionInterval=3600
## minorCompactionInterval@timerange0=1800
## 
## majorCompactionThreshold=0.3
## majorCompactionThreshold@timerange0=0.2
## majorCompactionThreshold@timerange1=0.5
## 
## majorCompactionInterval=86400 
## majorCompactionInterval=1800 
## 

# Port that bookie server listen on
# bookiePort=3181

# Set the network interface that the bookie should listen on.
# If not set, the bookie will listen on all interfaces.
# listeningInterface=eth0

# Whether the bookie allowed to use a loopback interface as its primary
# interface(i.e. the interface it uses to establish its identity)?
# By default, loopback interfaces are not allowed as the primary
# interface.
# Using a loopback interface as the primary interface usually indicates
# a configuration error. For example, its fairly common in some VPS setups
# to not configure a hostname, or to have the hostname resolve to
# 127.0.0.1. If this is the case, then all bookies in the cluster will
# establish their identities as 127.0.0.1:3181, and only one will be able
# to join the cluster. For VPSs configured like this, you should explicitly
# set the listening interface.
# allowLoopback=false

# Root zookeeper path to store ledger metadata
# This parameter is used by zookeeper-based ledger manager as a root znode to
# store all ledgers.
# zkLedgersRootPath=/ledgers
PRD.SP1.PRDSFSTORE2$zkLedgersRootPath=/prd2_ledgers
PRD.SP1.PRDSFSTORE3$zkLedgersRootPath=/prd3_ledgers

# Directory Bookkeeper outputs its write ahead log
# journalDirectory=/tmp/bk-txn
journalDirectory=/tmp/bk-txn

# Directory Bookkeeper outputs ledger snapshots
# could define multi directories to store snapshots, separated by ','
# For example:
# ledgerDirectories=/tmp/bk1-data,/tmp/bk2-data
# 
# Ideally ledger dirs and journal dir are each in a differet device,
# which reduce the contention between random i/o and sequential write.
# It is possible to run with a single disk, but performance will be significantly lower.
# ledgerDirectories=/tmp/bk-data
ledgerDirectories=/tmp/bk-data

# Directories to store index files. If not specified, will use ledgerDirectories to store.
# indexDirectories=/tmp/bk-data

# Allow the expansion of bookie storage capacity. Newly added ledger
# and index dirs must be empty.
# allowStorageExpansion=false
allowStorageExpansion=true

# Directory where LocalBookKeeper serializes the bookies config objects, which can be 
# later used by BookieShell for running against LocalBookKeeper.
# This config value should match DEFAULT_LOCALBOOKIES_CONFIG_DIR value in  
# bookkeeper/bookkeeper-server/bin/bookkeeper script file.
# localBookiesConfigDirectory=/tmp/localbookies-config

# Ledger Manager Class
# What kind of ledger manager is used to manage how ledgers are stored, managed
# and garbage collected. Try to read 'BookKeeper Internals' for detail info.
# ledgerManagerType=flat

# 'ledgerManagerType' is deprecated and it is replaced by 'ledgerManagerFactoryClass'
ledgerManagerFactoryClass=org.apache.bookkeeper.meta.LongHierarchicalLedgerManagerFactory

# Ledger storage implementation class
# ledgerStorageClass=org.apache.bookkeeper.bookie.SortedLedgerStorage

# disable it will make ledgerStorageClass use InterleavedLedgerStorage
# sortedLedgerStorageEnabled=true

# Enable/Disable entry logger preallocation
# if set to true, preallocation runs on a separate single-thread pool
# if false, preallocation runs synchronously on the thread doing addEntry
# disabling it results in more stable writes in case of
# collocated journal and ledger
# entryLogFilePreallocationEnabled=true
entryLogFilePreallocationEnabled=false

# skip list data size limitation
# skipListSizeLimit=67108864

# max size we should allocate from the skiplist arena. Allocations larger than this should
# be allocated directly by the VM to avoid fragmentation.
# skipListArenaMaxAllocSize=131072

# number of bytes to use as chunk allocation for org.apache.bookkeeper.bookie.SkipListArena
# skipListArenaChunkSize=4194304

# twitter's settings. seem to reduce frequency of memtable flushes.
skipListArenaChunkSize=2097152


# Max file size of entry logger, in bytes
# A new entry log file will be created when the old one reaches the file size limitation
# logSizeLimit=1073741824
logSizeLimit=1073741823

# Interval between sending an explicit LAC in seconds
# explicitLacInterval=0
explicitLacInterval=1

# Threshold of minor compaction
# For those entry log files whose remaining(used) size percentage reaches below
# this threshold will be compacted in a minor compaction.
# If it is set to less than zero, the minor compaction is disabled.
# Supports configuration override for specific time range.
# minorCompactionThreshold=0.2

# Interval to run minor compaction, in seconds
# If it is set to less than zero, the minor compaction is disabled.
# Supports configuration override for specific time range. 
# minorCompactionInterval=3600

# Threshold of major compaction
# For those entry log files whose remaining(used) size percentage reaches below
# this threshold will be compacted in a major compaction.
# Those entry log files whose remaining size percentage is still
# higher than the threshold will never be compacted.
# If it is set to less than zero, the major compaction is disabled.
# [twitter] reduce major compaction threshold to a low value to prevent bad force compaction behavior
# Supports configuration override for specific time range.
# majorCompactionThreshold=0.8
majorCompactionThreshold=0.6

# Interval to run major compaction, in seconds
# If it is set to less than zero, the major compaction is disabled.
# Supports configuration override for specific time range. 
# majorCompactionInterval=86400

# whether force compaction is allowed when disk full or almost full.
# Force GC may get some space back, but may also fill up disk space more
# quickly. This is because new log files are created before GC, while old
# garbage log files deleted after GC.
# Supports configuration override for specific time range.
# isForceGCAllowWhenNoSpace=false
isForceGCAllowWhenNoSpace=true

# Set the maximum number of entries which can be compacted without flushing.
# When compacting, the entries are written to the entrylog and the new offsets
# are cached in memory. Once the entrylog is flushed the index is updated with
# the new offsets. This parameter controls the number of entries added to the
# entrylog before a flush is forced. A higher value for this parameter means
# more memory will be used for offsets. Each offset consists of 3 longs.
# This parameter should _not_ be modified unless you know what you're doing.
# The default is 100,000.
# compactionMaxOutstandingRequests=100000

# Set the rate at which compaction will readd entries. The unit is adds per second.
# compactionRate=1000

# Throttle compaction by bytes or by entries. 
# isThrottleByBytes=false

# Set the rate at which compaction will readd entries. The unit is adds per second.
# compactionRateByEntries=1000

# Set the rate at which compaction will readd entries. The unit is bytes added per second.
# compactionRateByBytes=1000000

# Max file size of journal file, in mega bytes
# A new journal file will be created when the old one reaches the file size limitation
# journalMaxSizeMB=2048

# Max number of old journal file to kept
# Keep a number of old journal files would help data recovery in specia case
# journalMaxBackups=5

# How much space should we pre-allocate at a time in the journal
# improves stability of writes if journal and ledger share the device
# reduces IO spikes when reduced from default value
# journalPreAllocSizeMB=16
journalPreAllocSizeMB=4

# Size of the write buffers used for the journal
# improves stability of writes if journal and ledger share the device
# imporves write thtoughput comparing to default (64K)
# journalWriteBufferSizeKB=64
journalWriteBufferSizeKB=256

# Should we remove pages from page cache after force write
# journalRemoveFromPageCache=false
journalRemoveFromPageCache=true

# Should we group journal force writes, which optimize group commit
# for higher throughput
# journalAdaptiveGroupWrites=true

# Maximum latency to impose on a journal write to achieve grouping
# improves throughput under heavier load at expency of extra latency
# journalMaxGroupWaitMSec=2
journalMaxGroupWaitMSec=0

# Maximum writes to buffer to achieve grouping
# journalBufferedWritesThreshold=524288
journalBufferedWritesThreshold=262144

# Maximum entries to buffer to impose on a journal write to achieve grouping.
# Use journalBufferedWritesThreshold if this is set to zero or less than zero.
# journalBufferedEntriesThreshold=0
journalBufferedEntriesThreshold=180

# If we should flush the journal when journal queue is empty
# improves stability of writes if journal and ledger share the device
# journalFlushWhenQueueEmpty=false

# The number of threads that should handle journal callbacks
# improves stability of writes if journal and ledger share the device
# combined with increased numAddWorkerThreads improves throughput and stability.
# may need to be adjusted to match disk performance and number of disks in the system.
# numJournalCallbackThreads=1
numJournalCallbackThreads=12

# How long the interval to trigger next garbage collection, in milliseconds
# Since garbage collection is running in background, too frequent gc
# will heart performance. It is better to give a higher number of gc
# interval if there is enough disk capacity.
# Supports configuration override for specific time range.
# gcWaitTime=600000
gcWaitTime=1800000

# How long the interval to trigger next garbage collection of overreplicated
# ledgers, in milliseconds [Default: 1 day]. This should not be run very frequently since we read
# the metadata for all the ledgers on the bookie from zk
# gcOverreplicatedLedgerWaitTime=86400000

# Set the grace period which the rereplication worker will wait before
# fencing and rereplicating a ledger fragment which is still being written
# to, on bookie failure.
# The grace period allows the writer to detect the bookie failure, and and
# start writing to another ledger fragment. If the writer writes nothing
# during the grace period, the rereplication worker assumes that it has
# crashed and therefore fences the ledger, preventing any further writes to
# that ledger. Default value 30000 (30 secs)
# openLedgerRereplicationGracePeriod = 30000
openLedgerRereplicationGracePeriod = 600000

# How long the interval to flush ledger index pages to disk, in milliseconds
# Flushing index files will introduce much random disk I/O.
# If separating journal dir and ledger dirs each on different devices,
# flushing would not affect performance. But if putting journal dir
# and ledger dirs on same device, performance degrade significantly
# on too frequent flushing. You can consider increment flush interval
# to get better performance, but you need to pay more time on bookie
# server restart after failure.
# flushInterval=10000

# Entry log flush interval in bytes.
# Default is 0. 0 or less disables this feature and effectively flush
# happens on log rotation.
# Flushing in smaller chunks but more frequently reduces spikes in disk
# I/O. Flushing too frequently may also affect performance negatively.
# let's flush every 10M
# flushEntrylogBytes=0
flushEntrylogBytes=10485760

# Interval to watch whether bookie is dead or not, in milliseconds
# bookieDeathWatchInterval=1000

## zookeeper client settings

# A list of one of more servers on which zookeeper is running.
# The server list can be comma separated values, for example:
# zkServers=zk1:2181,zk2:2181,zk3:2181
zkServers=localhost:2181

# ZooKeeper client session timeout in milliseconds
# Bookie server will exit if it received SESSION_EXPIRED because it
# was partitioned off from ZooKeeper for more than the session timeout
# JVM garbage collection, disk I/O will cause SESSION_EXPIRED.
# Increment this value could help avoiding this issue
# zkTimeout=10000

## NIO Server settings

# This settings is used to enabled/disabled Nagle's algorithm, which is a means of
# improving the efficiency of TCP/IP networks by reducing the number of packets
# that need to be sent over the network.
# If you are sending many small messages, such that more than one can fit in
# a single IP packet, setting server.tcpnodelay to false to enable Nagle algorithm
# can provide better performance.
# Default value is true.
# serverTcpNoDelay=true

## ledger cache settings

# Max number of ledger index files could be opened in bookie server
# If number of ledger index files reaches this limitation, bookie
# server started to swap some ledgers from memory to disk.
# Too frequent swap will affect performance. You can tune this number
# to gain performance according your requirements.
# openFileLimit=20000

# Size of a index page in ledger cache, in bytes
# A larger index page can improve performance writing page to disk,
# which is efficent when you have small number of ledgers and these
# ledgers have similar number of entries.
# If you have large number of ledgers and each ledger has fewer entries,
# smaller index page would improve memory usage.
# pageSize=8192

# How many index pages provided in ledger cache
# If number of index pages reaches this limitation, bookie server
# starts to swap some ledgers from memory to disk. You can increment
# this value when you found swap became more frequent. But make sure
# pageLimit*pageSize should not more than JVM max memory limitation,
# otherwise you would got OutOfMemoryException.
# In general, incrementing pageLimit, using smaller index page would
# gain bettern performance in lager number of ledgers with fewer entries case
# If pageLimit is -1, bookie server will use 1/3 of JVM memory to compute
# the limitation of number of index pages.
# pageLimit=-1

# If all ledger directories configured are full, then support only read requests for clients.
# If "readOnlyModeEnabled=true" then on all ledger disks full, bookie will be converted
# to read-only mode and serve only read requests. Otherwise the bookie will be shutdown.
# By default this will be enabled.
# readOnlyModeEnabled=true

# For each ledger dir, maximum disk space which can be used.
# Default is 0.95f. i.e. 95% of disk can be used at most after which nothing will
# be written to that partition. If all ledger dir partions are full, then bookie
# will turn to readonly mode if 'readOnlyModeEnabled=true' is set, else it will
# shutdown.
# Valid values should be in between 0 and 1 (exclusive). 
# diskUsageThreshold=0.95
diskUsageThreshold=0.85

# the warning threshold for disk usage. If disk usage
# goes beyond this, a garbage collection cycle will be forced.
# diskUsageWarnThreshold=0.95
diskUsageWarnThreshold=0.8

# Disk check interval in milli seconds, interval to check the ledger dirs usage.
# diskCheckInterval=10000
diskCheckInterval=60000

# Interval at which the auditor will do a check of all ledgers in the cluster.
# By default this runs once a week. The interval is set in seconds.
# To disable the periodic check completely, set this to 0.
# Note that periodic checking will put extra load on the cluster, so it should
# not be run more frequently than once a day.
# auditorPeriodicCheckInterval=604800

# isAuditorPeriodicCheckOkToRunNow support configuration override for specific time range
# so it is possible to enable/disable AuditorPeriodicCheck depending on the system date/time
# so if the auditorPeriodicCheck is scheduled to execute now, but if isAuditorPeriodicCheckOkToRunNow is false,
# then Auditor will reschedule periodiccheck after auditorPeriodicCheckRetryInterval
# since isAuditorPeriodicCheckOkToRunNow is time controllable config, we can define timeranges for isAuditorPeriodicCheckOkToRunNow
# Example:
# timerange0.start=09:00:00
# timerange0.end=17:59:59.999
# 
# timerange1.start=22:00
# timerange1.end=23:00
# timerange1.day=Saturday,Sunday
# isAuditorPeriodicCheckOkToRunNow@timerange0=true
# isAuditorPeriodicCheckOkToRunNow@timerange1=false
# isAuditorPeriodicCheckOkToRunNow=true

# as mentioned above, if isAuditorPeriodicCheckOkToRunNow is false when it is time to execute PeriodicCheck, 
# then Auditor will reschedule it to execute after auditorPeriodicCheckRetryInterval
# auditorPeriodicCheckRetryInterval=3600

# The interval between auditor bookie checks.
# The auditor bookie check, checks ledger metadata to see which bookies should
# contain entries for each ledger. If a bookie which should contain entries is
# unavailable, then the ledger containing that entry is marked for recovery.
# Setting this to 0 disabled the periodic check. Bookie checks will still
# run when a bookie fails.
# The interval is specified in seconds.
# auditorPeriodicBookieCheckInterval=86400

# isAuditorPeriodicBookieCheckOkToRunNow support configuration override for specific time range
# so it is possible to enable/disable AuditorPeriodicBookieCheck depending on the system date/time
# so if the auditorPeriodicBookieCheck is scheduled to execute now, but if isAuditorPeriodicBookieCheckOkToRunNow is false,
# then Auditor will reschedule PeriodicBookieCheck after auditorPeriodicBookieCheckRetryInterval
# since isAuditorPeriodicBookieCheckOkToRunNow is time controllable config, we can define timeranges for isAuditorPeriodicBookieCheckOkToRunNow
# for examples please check isAuditorPeriodicCheckOkToRunNow
# isAuditorPeriodicBookieCheckOkToRunNow=true

# as mentioned above, if isAuditorPeriodicBookieCheckOkToRunNow is false when it is time to execute PeriodicBookieCheck, 
# then Auditor will reschedule it to execute after auditorPeriodicBookieCheckRetryInterval
# auditorPeriodicBookieCheckRetryInterval=3600

# number of threads that should handle write requests. if zero, the writes would
# be handled by netty threads directly.
# numAddWorkerThreads=1
numAddWorkerThreads=6

# number of threads that should handle read requests. if zero, the reads would
# be handled by netty threads directly.
# improves read throughput and latency. 
# needs to be adjusted to match disk performance and number of disks.
# numReadWorkerThreads=8
numReadWorkerThreads=18

# The number of bytes we should use as capacity for BufferedReadChannel. Default is 512 bytes.
# adjusted to load typical data entry (64K) + some overhead.
# values smaller than data entry size will result in multiple disk accesses (bad performance)
# significantly larger values willrresult in prefetch if unnecessary data (bad performance)
# alighen do 4K block
# readBufferSizeBytes=512
readBufferSizeBytes=69632

# The number of bytes used as capacity for the write buffer. Default is 64KB.
# improves stability of writes if journal and ledger share the device
# reduces IO spikes
# writeBufferSizeBytes=65536
writeBufferSizeBytes=524288

# Whether the bookie should use its hostname to register with the
# co-ordination service(eg: zookeeper service).
# When false, bookie will use its ipaddress for the registration.
# Defaults to false.
# useHostNameAsBookieID=false

# If bookie is using hostname for registration and in ledger metadata then
# whether to use short hostname or FQDN hostname. Defaults to false.
# useShortHostName=false

# Setting this to true will enable the logging for BK, outputting metrics to files
# enableStatistics=false
enableStatistics=true

# Enable statistics for LocalBookkeeper
enableLocalStats=false
LOCALBOX$enableLocalStats=true

# Stats Provider Class
statsProviderClass=org.apache.bookkeeper.stats.CodahaleMetricsProvider


# Graphite, CSV and Slf4j metrics reports output frequency, default is 60s
# see SdbStoreOps.git Prod-Operations/MetricStreamer/config/jobs/sfstore_node.json "sfstore_ar"
# for jetty metrics polling frequency configuration
codahaleStatsOutputFrequencySeconds=600

# prefix for defining a scope for the bookie or bookkeeper client metrics
codahaleStatsPrefix=ar

# directory for appending metrics in csv files
# codahaleStatsCSVEndpoint=/media/data/stats

# whether the Bookie itself can start auto-recovery service also or not
# autoRecoveryDaemonEnabled=false
autoRecoveryDaemonEnabled=true

# how long to wait, in seconds, before starting auto recovery of a lost bookie
# lostBookieRecoveryDelay=0
lostBookieRecoveryDelay=1800

# If present and > 0, stats are hosted.
jettyPort=2184
# Context path after domain to monitor. Must begin with / and not end with /
statServletContextPath=/stats/replication
# Endpoint to host metrics on. Hosted after [domain]/[servletContextPath]/. Must begin with / and not end with /
statServletEndpoint=/metrics.json

# If enabled, rest endpoints are enabled alongside stats on same jetty server.
enableRestEndpoints=true
restPackage=org.apache.bookkeeper.util
restServletContextPath=/rest

# Ensure that we start the user as only a certain user
# permittedStartupUsers=

# Entry formatter class to format entries. default is String formatter
# entryFormatterClass=org.apache.bookkeeper.util.StringEntryFormatter
entryFormatterClass=org.apache.bookkeeper.util.HexDumpEntryFormatter

# LedgerId formatter class to format ledgerids. default value is UUID formatter
# ledgerIdFormatterClass=org.apache.bookkeeper.util.LedgerIdFormatter$UUIDLedgerIdFormatter

# Minimum safe Usable size to be available in index directory for Bookie to create Index File while replaying 
# journal at the time of Bookie Start in Readonly Mode (in bytes)
# minUsableSizeForIndexFileCreation=104857600

# Configure the Bookie to allow/disallow multiple ledger/index directories in the same filesystem partition
# allowMultipleDirsUnderSamePartition=true
allowMultipleDirsUnderSamePartition=false

# Enable OrderedSafeExecutor stats
enableTaskExecutionStats=true

# SSL Provider (JDK or OpenSSL)
sslProvider=OpenSSL

# The path to class that provides security.
# sslProviderFactoryClass=
PRD.PRDSFSTORE.PRDSFSTORE$sslProviderFactoryClass=org.apache.bookkeeper.ssl.SSLContextFactory
PRD.SP1.PRDSFSTORE2$sslProviderFactoryClass=org.apache.bookkeeper.ssl.SSLContextFactory
PRD.SP1.PRDSFSTORE3$sslProviderFactoryClass=org.apache.bookkeeper.ssl.SSLContextFactory
PHX.SP1.GS1$sslProviderFactoryClass=org.apache.bookkeeper.ssl.SSLContextFactory
DFW.SP1.GS1$sslProviderFactoryClass=org.apache.bookkeeper.ssl.SSLContextFactory

# Type of security used by server
sslClientAuthentication=true

# Keyfile type
sslKeyFileType=PEM

# Keyfile location (path)
PRD.PRDSFSTORE.PRDSFSTORE$sslKeyFilePath=/sfs/sfsbuild/current/certs/server-key.pem
sslKeyFilePath=/etc/pki_service/sfstore/client/keys/client-key.pem

# Keyfile password path, if the keyfile is protected by a password
#sslKeyFilePasswordPath=

# Certificate path
PRD.PRDSFSTORE.PRDSFSTORE$sslCertificatePath=/sfs/sfsbuild/current/certs/server-cert.pem
sslCertificatePath=/etc/pki_service/sfstore/client/certificates/client.pem

# Trustfile type
sslTrustFileType=PEM

# Trustfile location (path)
PRD.PRDSFSTORE.PRDSFSTORE$sslTrustFilePath=/sfs/sfsbuild/current/certs/ca-cert.pem
sslTrustFilePath=/etc/pki_service/ca/cacerts.pem

# Trustfile password path, if the trustfile is protected by a password
#sslTrustFilePasswordPath=
